{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINIMAL EXAMPLE OF JUPYTER NOTEBOOK WHICH CAN BE RUN WITH CROMWELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem is that it produces run2.html and trial_v1_movie_rec.gif in local folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib\n",
    "#!pip install pyro-ppl --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import moviepy.editor as mpy\n",
    "import numpy as np\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" #for debugging, it decrease performance dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyro-ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from vae_model import * \n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "# Set up pyro environment\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "# Check versions\n",
    "print(\"pyro.__version__  --> \",pyro.__version__)\n",
    "print(\"torch.__version__ --> \",torch.__version__)\n",
    "assert(pyro.__version__.startswith('1.2'))\n",
    "assert(torch.__version__.startswith('1.4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read two json files and combine in single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_json_as_dict(\"parameters.json\")\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROMWELL will localize: \n",
    "# gs://ld-data-bucket/data/fashionmnist_train.pkl -> execution_dir/ld-data-bucket/data/fashionmnist_train.pkl\n",
    "# Therefore I just need to remove  \"gs://\"\n",
    "# Note that every path is relative to the execution_dir\n",
    "\n",
    "def remove_prefix(text, prefix):\n",
    "    if text.startswith(prefix):\n",
    "        return text[len(prefix):]\n",
    "    return text  # or whatever\n",
    "\n",
    "train_file = remove_prefix(params[\"wdl.file_train\"],\"gs://\")\n",
    "test_file = remove_prefix(params[\"wdl.file_train\"],\"gs://\")\n",
    "ckpt_file = remove_prefix(params[\"wdl.file_ckpt\"],\"gs://\")\n",
    "dir_output = params[\"wdl.dir_output\"]\n",
    "\n",
    "# create output directionry if it does nto exists\n",
    "try:\n",
    "    os.mkdir(dir_output)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Save file to output dir\n",
    "json_param_file = os.path.join(dir_output, \"parameters.json\")\n",
    "save_dict_as_json(params,json_param_file)\n",
    "\n",
    "# checks\n",
    "assert os.path.isfile(train_file)\n",
    "assert os.path.isfile(test_file)\n",
    "if params[\"simulation\"][\"type\"] != \"scratch\":\n",
    "    assert os.path.isfile(ckpt_file)\n",
    "    \n",
    "print(train_file)\n",
    "print(test_file)\n",
    "print(dir_output)\n",
    "print(json_param_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"get the data\")\n",
    "train_dataset = DatasetInMemory(train_file,use_cuda=torch.cuda.is_available())\n",
    "test_dataset  = DatasetInMemory(test_file,use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VaeClass(params)\n",
    "optimizer = instantiate_optimizer(vae, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 possible simulation types: scratch, resumed, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"simulation type = \"+str(params[\"simulation\"][\"type\"]))\n",
    "\n",
    "if (params[\"simulation\"][\"type\"] == \"scratch\"):\n",
    "    \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"resumed\"):\n",
    "        \n",
    "    resumed = load_info(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                        load_epoch=True, \n",
    "                        load_history=True)\n",
    "    epoch_restart = resumed.epoch\n",
    "    history_dict = resumed.history_dict\n",
    "    min_test_loss = min(history_dict[\"test_loss\"])\n",
    "    \n",
    "    load_model_optimizer(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                         model=vae,\n",
    "                         optimizer=optimizer)\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"pretrained\"):\n",
    "       \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "    \n",
    "    load_model_optimizer(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                         model=vae,\n",
    "                         optimizer=None)\n",
    "    \n",
    "# instantiate the scheduler if necessary    \n",
    "if params[\"training\"][\"scheduler_is_active\"]:\n",
    "    scheduler = instantiate_scheduler(optimizer, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FREQUENCY = params[\"training\"][\"TEST_FREQUENCY\"]\n",
    "CHECKPOINT_FREQUENCY = params[\"training\"][\"CHECKPOINT_FREQUENCY\"]\n",
    "NUM_EPOCHS = params[\"training\"][\"EPOCHS\"]\n",
    "BATCH_SIZE = params[\"training\"][\"batch_size\"]\n",
    "\n",
    "for delta_epoch in range(1,NUM_EPOCHS+1):\n",
    "    epoch = delta_epoch+epoch_restart\n",
    "    vae.train()   \n",
    "    \n",
    "    #with torch.autograd.set_detect_anomaly(True):\n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "        train_metrics = train_one_epoch(vae, \n",
    "                                        train_dataset, \n",
    "                                        optimizer, \n",
    "                                        BATCH_SIZE, \n",
    "                                        verbose=(epoch==0), \n",
    "                                        weight_clipper=None)\n",
    "        s = pretty_print_metrics(epoch, train_metrics, is_train=True)\n",
    "        print(s)\n",
    "            \n",
    "        \n",
    "        history_dict = add_named_tuple_to_dictionary(namedtuple=train_metrics, \n",
    "                                                     dictionary=history_dict,\n",
    "                                                     key_prefix=\"train_\")\n",
    "        \n",
    "    if params[\"training\"][\"scheduler_is_active\"]:\n",
    "        scheduler.step(epoch=epoch)\n",
    "    \n",
    "    if(epoch % TEST_FREQUENCY == 0):\n",
    "        vae.eval()\n",
    "        test_metrics = train_one_epoch(vae, \n",
    "                                       test_dataset, \n",
    "                                       optimizer, \n",
    "                                       BATCH_SIZE, \n",
    "                                       verbose=(epoch==0), \n",
    "                                       weight_clipper=None)\n",
    "        \n",
    "        s = pretty_print_metrics(epoch, test_metrics, is_train=False)\n",
    "        print(s)\n",
    "                \n",
    "        history_dict = add_named_tuple_to_dictionary(namedtuple=test_metrics, \n",
    "                                                     dictionary=history_dict,\n",
    "                                                     key_prefix=\"test_\")\n",
    "        \n",
    "        test_loss = test_metrics[\"loss\"]\n",
    "        min_test_loss = min(min_test_loss, test_loss)\n",
    "            \n",
    "        #if((test_loss == min_test_loss) or ((epoch % CHECKPOINT_FREQUENCY) == 0)): \n",
    "        if((test_loss == min_test_loss) or ((epoch % TEST_FREQUENCY) == 0)):\n",
    "            checkpoint_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "            history_file = os.path.join(dir_output, \"history_\"+str(epoch)+\".pkl\")\n",
    "            \n",
    "            save_everything(model=vae, \n",
    "                            optimizer=optimizer, \n",
    "                            history_dict=history_dict, \n",
    "                            epoch=epoch, \n",
    "                            params_dict=params, \n",
    "                            path=checkpoint_file)\n",
    "            \n",
    "            save_dict_as_json(history_dict, path=history_file)\n",
    "            print(\"saved files -> \"+checkpoint_file+\"  \"+history_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history_dict.items():\n",
    "    print(k,\" -->\", history_dict[k][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign=1\n",
    "\n",
    "fontsize=10\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('REC',fontsize=fontsize)\n",
    "ax.set_ylabel('REG',fontsize=fontsize)\n",
    "\n",
    "ax.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), sign*np.array(history_dict[\"train_loss\"])+y_shift,'-')\n",
    "ax.plot(np.arange(x_shift, x_shift+len(history_dict[\"test_loss\"])*TEST_FREQUENCY,TEST_FREQUENCY), sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('LOSS = - ELBO')\n",
    "ax.set_title('Training procedure')\n",
    "ax.grid(True)\n",
    "ax.legend(['train', 'test_clean', 'test_noisy'])\n",
    "\n",
    "fig.tight_layout()\n",
    "tmp_file = os.path.join(dir_output, \"loss.png\")\n",
    "fig.savefig(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "how_many = 2000\n",
    "scale= 1\n",
    "N = len(history_dict[\"train_kl\"][-how_many :])\n",
    "colors = np.arange(0.0,N,1.0)/N\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "#plt.yscale('log')\n",
    "#plt.xlim(xmin=1.0, xmax=1.5)\n",
    "ax.set_xlabel('REC',fontsize=fontsize)\n",
    "ax.set_ylabel('REG',fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax.scatter(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :],c=colors)\n",
    "ax.plot(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :], '-')\n",
    "ax.grid()\n",
    "#plt.xlim(xmax=2.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "tmp_file = os.path.join(dir_output, \"rec_kl_trajectory.png\")\n",
    "fig.savefig(tmp_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_list = [291, 413, 133, 148, 1,2,3,4,5,6,7,8,9]\n",
    "reference_imgs, labels=test_dataset.load(batch_size=9, indices=tmp_list)\n",
    "metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "\n",
    "reconstruction_file = os.path.join(dir_output, \"imgs_reconstructed.png\")\n",
    "reference_file = os.path.join(dir_output, \"imgs_reference.png\")\n",
    "\n",
    "imgs_ref = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "imgs_ref.savefig(reference_file)\n",
    "\n",
    "imgs_rec = show_batch(inference.reconstruction, n_col=3,n_padding=4, title=\"REC_IMG\")\n",
    "imgs_rec.savefig(reconstruction_file)\n",
    "\n",
    "display(imgs_rec, imgs_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=\"xxx\"\n",
    "a = show_batch(inference.reconstruction[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_filenames = []\n",
    "\n",
    "for epoch in range(0,30,TEST_FREQUENCY):\n",
    "    if(epoch<10):\n",
    "        label =\"_000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"_00\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"_0\"+str(epoch)\n",
    "    elif(epoch<10000):\n",
    "        label = \"_\"+str(epoch)\n",
    "    else:\n",
    "        raise Exception\n",
    "\n",
    "    try:\n",
    "        checkpoint_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "        _ = load_model_optimizer(path=checkpoint_file, model=vae, optimizer=None)\n",
    "        metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "        tmp_fig = show_batch(inference.reconstruction[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        tmp_rec_file = os.path.join(dir_output, \"imgs_rec\"+label+\".png\")\n",
    "        rec_filenames.append(tmp_rec_file)\n",
    "        tmp_fig.savefig(tmp_rec_file, bbox_inches='tight') \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(rec_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_rec(n):\n",
    "    tmp = Image(filename=rec_filenames[n])\n",
    "    return display(tmp)\n",
    "\n",
    "def show_frame_all(n):\n",
    "    c = Image(filename=rec_filenames[n])\n",
    "    return display(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make gif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rec_file_local = \"movie_rec.gif\"\n",
    "movie_rec_file_absolute = os.path.join(dir_output, movie_rec_file_local)\n",
    "\n",
    "frame_per_second = 2\n",
    "im = mpy.ImageSequenceClip(rec_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_rec_file_local, fps=frame_per_second)\n",
    "im.write_gif(movie_rec_file_absolute, fps=frame_per_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_rec_file_local+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_rec(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
