{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINIMAL EXAMPLE OF JUPYTER NOTEBOOK WHICH CAN BE RUN WITH CROMWELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem is that it produces run2.html and trial_v1_movie_rec.gif in local folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import moviepy.editor as mpy\n",
    "import numpy as np\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" #for debugging, it decrease performance dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyro.__version__  -->  0.4.0\n",
      "torch.__version__ -->  1.2.0\n"
     ]
    }
   ],
   "source": [
    "from utilities import *\n",
    "from model import * \n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "# Set up pyro environment\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "# Check versions\n",
    "print(\"pyro.__version__  --> \",pyro.__version__)\n",
    "print(\"torch.__version__ --> \",torch.__version__)\n",
    "assert(pyro.__version__.startswith('0.4'))\n",
    "assert(torch.__version__.startswith('1.2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read jason file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_local_machine': True, 'cloud': {'__comment': 'cloud parameters', 'VM_image': 'us.gcr.io/broad-dsde-methods/pyro@sha256:4c4745a22762852cf14263c537f645182df3557a1163527a3aaeca7e5da37b4225', 'GPU_type': 'tesla_k80', 'results_folder': 'gs://ld-results-bucket/fashionmnist_results', 'train_dataset': 'gs://ld-data-bucket/data/fashionmnist_train.pkl', 'test_dataset': 'gs://ld-data-bucket/data/fashionmnist_test.pkl'}, 'simulation': {'__comment': 'there are 3 types of runs: scratch resume pretrain', 'name': 'trial_v1', 'type': 'scratch', 'path_to_file': None}, 'architecture': {'__comment': 'parameters specifying the architecture of the model', 'dim_zwhat': 25, 'width_input_image': 28, 'ch_input_image': 1}, 'loss': {'__comment': 'parameter of the observation model', 'mse_sigma': 0.1}, 'optimizer': {'__comment': 'which optimizer to use', 'type': 'adam', 'lr': 0.001, 'betas': [0.9, 0.999], 'eps': 1e-08}, 'training': {'__comment': 'parameter of the observation model', 'EPOCHS': 1, 'TEST_FREQUENCY': 5, 'CHECKPOINT_FREQUENCY': 20, 'batch_size': 64, 'scheduler_is_active': False, 'scheduler_type': 'step_LR', 'scheduler_step_size': 100, 'scheduler_gamma': 0.75}}\n"
     ]
    }
   ],
   "source": [
    "params = load_json_as_dict(\"./input_params.json\")  \n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fashionmnist_results/input_params.json\n",
      "./data/fashionmnist_train.pkl\n",
      "./data/fashionmnist_test.pkl\n",
      "./fashionmnist_results/trial_v1.log\n",
      "./fashionmnist_results/input_params.json\n"
     ]
    }
   ],
   "source": [
    "if params[\"use_local_machine\"]:\n",
    "            \n",
    "    # prepare input file\n",
    "    train_tmp = params[\"cloud\"][\"train_dataset\"].split(\"/\")\n",
    "    train_file = os.path.join(\".\",train_tmp[-2],train_tmp[-1])\n",
    "    test_tmp = params[\"cloud\"][\"test_dataset\"].split(\"/\")\n",
    "    test_file = os.path.join(\".\",test_tmp[-2],test_tmp[-1])\n",
    "    \n",
    "    # prepare output file\n",
    "    simulation_name = params[\"simulation\"][\"name\"]\n",
    "    output_dir = os.path.basename(params[\"cloud\"][\"results_folder\"])\n",
    "    json_param_file = os.path.join(\".\",output_dir, \"input_params.json\")\n",
    "    log_file = os.path.join(\".\",output_dir, str(simulation_name) + \".log\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise Exception\n",
    "    # prepare input file\n",
    "    train_file = params[\"cloud\"][\"train_dataset\"]\n",
    "    test_file = params[\"cloud\"][\"test_dataset\"]\n",
    "    \n",
    "    # prepare output file\n",
    "    simulation_name = params[\"simulation\"][\"name\"]\n",
    "    result_dir = params[\"cloud\"][\"results_folder\"]\n",
    "    json_param_file = os.path.join(output_dir, \"input_params.json\")\n",
    "    log_file = os.path.join(output_dir, str(simulation_name) + \".log\")\n",
    "    \n",
    "print(train_file)\n",
    "print(test_file)\n",
    "print(log_file)\n",
    "print(json_param_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start logging some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"luca_logging: %(message)s\",\n",
    "                    filename=log_file,\n",
    "                    filemode=\"w\")\n",
    "console = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\"luca_logging: %(message)s\")\n",
    "console.setFormatter(formatter)  # Use the same format for stdout.\n",
    "logging.getLogger('').addHandler(console)  # Log to stdout and a file.\n",
    "\n",
    "# Log the start time.\n",
    "logging.info(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"saving input json in output directory\")\n",
    "save_dict_as_json(params,json_param_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"get the data\")\n",
    "train_dataset = DatasetInMemory(train_file,use_cuda=torch.cuda.is_available())\n",
    "test_dataset  = DatasetInMemory(test_file,use_cuda=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Instantiate model and optimizer\")\n",
    "vae = VaeClass(params)\n",
    "optimizer = instantiate_optimizer(vae, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 possible simulation types: scratch, resumed, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"simulation type = \"+str(params[\"simulation\"][\"type\"]))\n",
    "\n",
    "if (params[\"simulation\"][\"type\"] == \"scratch\"):\n",
    "    \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"resumed\"):\n",
    "        \n",
    "    resumed = load_info(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                        load_epoch=True, \n",
    "                        load_history=True)\n",
    "    epoch_restart = resumed.epoch\n",
    "    history_dict = resumed.history_dict\n",
    "    min_test_loss = min(history_dict[\"test_loss\"])\n",
    "    \n",
    "    load_model_optimizer(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                         model=vae,\n",
    "                         optimizer=optimizer)\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"pretrained\"):\n",
    "       \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "    \n",
    "    load_model_optimizer(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                         model=vae,\n",
    "                         optimizer=None)\n",
    "    \n",
    "# instantiate the scheduler if necessary    \n",
    "if params[\"training\"][\"scheduler_is_active\"]:\n",
    "    scheduler = instantiate_scheduler(optimizer, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FREQUENCY = params[\"training\"][\"TEST_FREQUENCY\"]\n",
    "CHECKPOINT_FREQUENCY = params[\"training\"][\"CHECKPOINT_FREQUENCY\"]\n",
    "NUM_EPOCHS = params[\"training\"][\"EPOCHS\"]\n",
    "BATCH_SIZE = params[\"training\"][\"batch_size\"]\n",
    "\n",
    "logging.info(\"start training -> \"+datetime.now().strftime('%Y-%m-%d %H:%M:%S')) \n",
    "try:\n",
    "    for delta_epoch in range(1,NUM_EPOCHS+1):\n",
    "        epoch = delta_epoch+epoch_restart\n",
    "        vae.train()   \n",
    "        \n",
    "        #with torch.autograd.set_detect_anomaly(True):\n",
    "        with torch.autograd.set_detect_anomaly(False):\n",
    "            train_metrics = train_one_epoch(vae, \n",
    "                                            train_dataset, \n",
    "                                            optimizer, \n",
    "                                            BATCH_SIZE, \n",
    "                                            verbose=False, \n",
    "                                            weight_clipper=None)\n",
    "            s = pretty_print_metrics(epoch, train_metrics, is_train=True)\n",
    "            logging.info(s)\n",
    "                \n",
    "            \n",
    "            history_dict = add_named_tuple_to_dictionary(namedtuple=train_metrics, \n",
    "                                                         dictionary=history_dict,\n",
    "                                                         key_prefix=\"train_\")\n",
    "            \n",
    "        if params[\"training\"][\"scheduler_is_active\"]:\n",
    "            scheduler.step(epoch=epoch)\n",
    "        \n",
    "        if(epoch % TEST_FREQUENCY == 0):\n",
    "            vae.eval()\n",
    "            test_metrics = train_one_epoch(vae, \n",
    "                                           test_dataset, \n",
    "                                           optimizer, \n",
    "                                           BATCH_SIZE, \n",
    "                                           verbose=False, \n",
    "                                           weight_clipper=None)\n",
    "            \n",
    "            s = pretty_print_metrics(epoch, test_metrics, is_train=False)\n",
    "            logging.info(s)\n",
    "                    \n",
    "            history_dict = add_named_tuple_to_dictionary(namedtuple=test_metrics, \n",
    "                                                         dictionary=history_dict,\n",
    "                                                         key_prefix=\"test_\")\n",
    "            \n",
    "            test_loss = test_metrics[\"loss\"]\n",
    "            min_test_loss = min(min_test_loss, test_loss)\n",
    "                \n",
    "            #if((test_loss == min_test_loss) or ((epoch % CHECKPOINT_FREQUENCY) == 0)): \n",
    "            if((test_loss == min_test_loss) or ((epoch % TEST_FREQUENCY) == 0)):\n",
    "                checkpoint_file = os.path.join(output_dir, simulation_name+\"_ckp_\"+str(epoch)+\".pkl\")\n",
    "                history_file = os.path.join(output_dir, simulation_name+\"_history_\"+str(epoch)+\".pkl\")\n",
    "                \n",
    "                save_everything(model=vae, \n",
    "                                optimizer=optimizer, \n",
    "                                history_dict=history_dict, \n",
    "                                epoch=epoch, \n",
    "                                params_dict=params, \n",
    "                                path=checkpoint_file)\n",
    "                \n",
    "                save_dict_as_json(history_dict, path=history_file)\n",
    "                logging.info(\"saved files -> \"+checkpoint_file+\"  \"+history_file)\n",
    "                \n",
    "    logging.info(\"end training -> \"+datetime.now().strftime('%Y-%m-%d %H:%M:%S')) \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logging.info(\"Keyboard interrupt.  Terminated without saving.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history_dict.items():\n",
    "    print(k,\" -->\", history_dict[k][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign=1\n",
    "\n",
    "fontsize=10\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('REC',fontsize=fontsize)\n",
    "ax.set_ylabel('REG',fontsize=fontsize)\n",
    "\n",
    "ax.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), sign*np.array(history_dict[\"train_loss\"])+y_shift,'-')\n",
    "ax.plot(np.arange(x_shift, x_shift+len(history_dict[\"test_loss\"])*TEST_FREQUENCY,TEST_FREQUENCY), sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('LOSS = - ELBO')\n",
    "ax.set_title('Training procedure')\n",
    "ax.grid(True)\n",
    "ax.legend(['train', 'test_clean', 'test_noisy'])\n",
    "\n",
    "fig.tight_layout()\n",
    "tmp_file = os.path.join(output_dir, simulation_name+\"_train.png\")\n",
    "fig.savefig(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "how_many = 2000\n",
    "scale= 1\n",
    "N = len(history_dict[\"train_kl\"][-how_many :])\n",
    "colors = np.arange(0.0,N,1.0)/N\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "#plt.yscale('log')\n",
    "#plt.xlim(xmin=1.0, xmax=1.5)\n",
    "ax.set_xlabel('REC',fontsize=fontsize)\n",
    "ax.set_ylabel('REG',fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax.scatter(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :],c=colors)\n",
    "ax.plot(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :], '-')\n",
    "ax.grid()\n",
    "#plt.xlim(xmax=2.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "tmp_file = os.path.join(output_dir, simulation_name+\"_kl_trajectory.png\")\n",
    "fig.savefig(tmp_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_list = [291, 413, 133, 148, 1,2,3,4,5,6,7,8,9]\n",
    "reference_imgs, labels=test_dataset.load(batch_size=9, indices=tmp_list)\n",
    "metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "\n",
    "reconstruction_file = os.path.join(output_dir, simulation_name+\"_reconstruction.png\")\n",
    "reference_file = os.path.join(output_dir, simulation_name+\"_reference.png\")\n",
    "\n",
    "imgs_ref = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "imgs_ref.savefig(reference_file)\n",
    "\n",
    "imgs_rec = show_batch(inference.reconstruction, n_col=3,n_padding=4, title=\"REC_IMG\")\n",
    "imgs_rec.savefig(reconstruction_file)\n",
    "\n",
    "display(imgs_rec, imgs_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=\"xxx\"\n",
    "a = show_batch(inference.reconstruction[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_filenames = []\n",
    "\n",
    "for epoch in range(0,30,TEST_FREQUENCY):\n",
    "    if(epoch<10):\n",
    "        label =\"_000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"_00\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"_0\"+str(epoch)\n",
    "    elif(epoch<10000):\n",
    "        label = \"_\"+str(epoch)\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    try:\n",
    "        checkpoint_file = os.path.join(output_dir, simulation_name+\"_ckp_\"+str(epoch)+\".pkl\")\n",
    "        _ = load_model_optimizer(path=checkpoint_file, model=vae, optimizer=None)\n",
    "        metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "        tmp_fig = show_batch(inference.reconstruction[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        tmp_rec_file = os.path.join(output_dir, simulation_name+label+\"_rec.png\")\n",
    "        rec_filenames.append(tmp_rec_file)\n",
    "        tmp_fig.savefig(tmp_rec_file, bbox_inches='tight') \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(rec_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_rec(n):\n",
    "    tmp = Image(filename=rec_filenames[n])\n",
    "    return display(tmp)\n",
    "\n",
    "def show_frame_all(n):\n",
    "    c = Image(filename=rec_filenames[n])\n",
    "    return display(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a gif file\n",
    "#name_movie = \"baseline_new_loss_v2.gif\"\n",
    "movie_rec_file_local = os.path.join(\"./\", simulation_name+\"_movie_rec.gif\")\n",
    "movie_rec_file_absolute = os.path.join(output_dir, simulation_name+\"_movie_rec.gif\")\n",
    "\n",
    "frame_per_second = 2\n",
    "im = mpy.ImageSequenceClip(rec_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_rec_file_local, fps=frame_per_second)\n",
    "im.write_gif(movie_rec_file_absolute, fps=frame_per_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_rec_file_local+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_rec(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
