{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINIMAL EXAMPLE OF JUPYTER NOTEBOOK WHICH CAN BE RUN WITH CROMWELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" #for debugging, it decrease performance dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilities import show_batch, save_obj, load_obj \n",
    "from utilities import load_json_as_dict, save_dict_as_json, DatasetInMemory\n",
    "from utilities import train_one_epoch, evaluate_one_epoch\n",
    "from model import VaeClass \n",
    "\n",
    "#!pip install moviepy\n",
    "from IPython.display import Image, display, HTML\n",
    "import moviepy.editor as mpy\n",
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "# Set up pyro environment\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "# Check versions\n",
    "print(\"pyro.__version__  --> \",pyro.__version__)\n",
    "print(\"torch.__version__ --> \",torch.__version__)\n",
    "assert(pyro.__version__.startswith('0.4'))\n",
    "assert(torch.__version__.startswith('1.2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read jason file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_json_as_dict(\"./input_params.json\")  \n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_machine = True\n",
    "if local_machine:\n",
    "    output_dir = \"/Users/ldalessi/cromwell_for_ML/RESULTS/\"\n",
    "    input_dir = \"/Users/ldalessi/cromwell_for_ML/DATA/\"\n",
    "    train_file = input_dir+str(params[\"cloud\"][\"train_dataset\"])+\".pkl\"\n",
    "    test_file = input_dir+str(params[\"cloud\"][\"test_dataset\"])+\".pkl\"\n",
    "    train_dataset = DatasetInMemory(train_file,use_cuda=torch.cuda.is_available())\n",
    "    test_dataset  = DatasetInMemory(test_file,use_cuda=torch.cuda.is_available())\n",
    "else:\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"run_type\"][\"from_scratch\"]:\n",
    "    \n",
    "\n",
    "    epoch_restart = -1\n",
    "    min_loss = 99999999\n",
    "    history_dict = {}\n",
    "    vae = VaeClass(params)\n",
    "    optimizer = instantiate_optimizer(model, params):\n",
    "    \n",
    "else:\n",
    "    \n",
    "    resumed = load_everyhting(model=None, optimizer=None, params[\"run_type\"][\"from_scratch\"])\n",
    "    \n",
    "    params = resumed.params\n",
    "    epoch_restart = resumed.epoch\n",
    "    history_dict = resumed.history_dict\n",
    "    vae = resumed.model\n",
    "    optimizer = resumed.optimizer\n",
    "    \n",
    "\n",
    "descriptor = params[\"run_type\"][\"identifier\"]\n",
    "name_vae          = descriptor+\"_vae\"\n",
    "name_history      = descriptor+\"_hystory\"\n",
    "    \n",
    "save_dict_as_json(params,output_dir+\"input_params.json\")\n",
    "\n",
    "if params[\"training\"][\"scheduler_is_active\"]:\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                step_size=params[\"training\"][\"step_size\"],\n",
    "                                                gamma=params[\"training\"][\"gamma\"],\n",
    "                                                last_epoch=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FREQUENCY = params[\"training\"][\"TEST_FREQUENCY\"]\n",
    "WRITE_FREQUENCY = params[\"training\"][\"WRITE_FREQUENCY\"]\n",
    "NUM_EPOCHS = params[\"training\"][\"EPOCHS\"]\n",
    "BATCH_SIZE = params[\"training\"][\"batch_size\"]\n",
    "    \n",
    "for delta_epoch in range(1,NUM_EPOCHS+1):\n",
    "    epoch = delta_epoch+epoch_restart\n",
    "    vae.train()   \n",
    "    \n",
    "    #with torch.autograd.set_detect_anomaly(True):\n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "        metric_av = train_one_epoch(vae, train_dataset, optimizer, BATCH_SIZE, verbose=False, weight_clipper=None)\n",
    "    if params[\"training\"][\"scheduler_is_active\"]:\n",
    "        scheduler.step(epoch=epoch)\n",
    "    \n",
    "    for k,v in metric_av.items():\n",
    "        try: \n",
    "            history_dict[\"train_\"+k].append(v)   \n",
    "        except KeyError:\n",
    "            history_dict[\"train_\"+k] = [v]\n",
    "        \n",
    "    print(\"[epoch %03d] train loss: %.4f NLL: %.4f KL %.4f\" % (epoch, history_dict[\"train_loss\"][-1], history_dict[\"train_nll\"][-1], history_dict[\"train_kl\"][-1]))\n",
    "          \n",
    "    if(epoch % TEST_FREQUENCY == 0):\n",
    "        vae.eval()\n",
    "        metric_av = train_one_epoch(vae, train_dataset, optimizer, BATCH_SIZE, verbose=False, weight_clipper=None)\n",
    "        test_loss = metric_av[\"loss\"] \n",
    "        min_loss = test_loss if test_loss < min_loss else min_loss\n",
    "        for k,v in metric_av.items():\n",
    "            try: \n",
    "                history_dict[\"test_\"+k].append(v)   \n",
    "            except KeyError:\n",
    "                history_dict[\"test_\"+k] = [v]\n",
    "            \n",
    "        if((test_loss == min_loss) or ((epoch % WRITE_FREQUENCY) == 0)): \n",
    "            save_everything(vae, optimizer, history_dict, epoch, params, output_dir+name_vae+\"_\"+str(epoch)+\".pkl\"):\n",
    "            save_dict_as_json(history_dict, output_dir+name_history+\"_\"+str(epoch)+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history_dict.items():\n",
    "    print(k,\" -->\", history_dict[k][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign=1\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), sign*np.array(history_dict[\"train_loss\"])+y_shift,'-')\n",
    "plt.plot(np.arange(x_shift, x_shift+len(history_dict[\"test_loss\"])*TEST_FREQUENCY,TEST_FREQUENCY), sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('LOSS = - ELBO')\n",
    "plt.title('Training procedure')\n",
    "#plt.ylim(ymax=2)\n",
    "plt.grid(True)\n",
    "plt.legend(['train', 'test_clean', 'test_noisy'])\n",
    "#plt.show()\n",
    "from matplotlib import pyplot as plt\n",
    "plt.savefig(output_dir+name_vae+'_train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "how_many = 2000\n",
    "scale= 1\n",
    "N = len(history_dict[\"train_kl\"][-how_many :])\n",
    "colors = np.arange(0.0,N,1.0)/N\n",
    "\n",
    "#plt.yscale('log')\n",
    "#plt.xlim(xmin=1.0, xmax=1.5)\n",
    "plt.xlabel('REC',fontsize=fontsize)\n",
    "plt.ylabel('REG',fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "plt.scatter(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :],c=colors)\n",
    "plt.plot(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :], '-')\n",
    "plt.grid()\n",
    "#plt.xlim(xmax=2.5)\n",
    "plt.savefig(output_dir+name_vae+'_kl_trajectory.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as mp\n",
    "\n",
    "tmp_list = [291, 413, 133, 148, 1,2,3,4,5,6,7,8,9]\n",
    "reference_imgs, labels=test_dataset.load(batch_size=9, indices=tmp_list)\n",
    "save_obj(reference_imgs ,output_dir+name_vae+\"reference_img.pkl\")\n",
    "\n",
    "#reference_imgs = load_obj(output_dir+name_vae+\"reference_img.pkl\")\n",
    "\n",
    "imgs_ref = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "imgs_ref.savefig(output_dir+name_vae+'_reference.png')\n",
    "display(imgs_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean vs Noisy reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "\n",
    "imgs_rec = show_batch(inference.reconstruction, n_col=3,n_padding=4, title=\"REC_IMG\")\n",
    "imgs_rec.savefig(output_dir+name_vae+'_reconstruction.png')\n",
    "display(imgs_rec, imgs_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=\"xxx\"\n",
    "tmp = show_batch(inference.reconstruction[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "display(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_rec_files = []\n",
    "list_of_map_files = []\n",
    "list_of_bg_files = []\n",
    "#mpl.interactive(False)\n",
    "\n",
    "\n",
    "for epoch in range(0,700,1):\n",
    "    if(epoch<10):\n",
    "        label =\"_000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"_00\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"_0\"+str(epoch)\n",
    "    elif(epoch<10000):\n",
    "        label = \"_\"+str(epoch)\n",
    "    else:\n",
    "        raise Exception\n",
    "    \n",
    "    try:\n",
    "        _ = load_everything(vae, optimizer, output_dir+name_vae+\"_\"+str(epoch)+\".pkl\")\n",
    "    except:\n",
    "        print(\"merda\")\n",
    "        pass\n",
    "        \n",
    "    try:\n",
    "        metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "        tmp = show_batch(inference.reconstruction[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        name_output_rec = name_vae+label+'rec.png'\n",
    "        list_of_rec_files.append(name_output_rec)\n",
    "        tmp.savefig(output_dir+name_output_rec, bbox_inches='tight') \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(list_of_rec_files)\n",
    "print(list_of_map_files)\n",
    "print(list_of_bg_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate filenames and directory\n",
    "rec_filenames = [write_dir+name for name in list_of_rec_files]\n",
    "map_filenames = [write_dir+name for name in list_of_map_files]\n",
    "bg_filenames = [write_dir+name for name in list_of_bg_files]\n",
    "\n",
    "print(rec_filenames)\n",
    "print(map_filenames)\n",
    "print(bg_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_rec(n):\n",
    "    return display.Image(filename=rec_filenames[n])\n",
    "\n",
    "def show_frame_all(n):\n",
    "    c = Image(filename=rec_filenames[n])\n",
    "    return display(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a gif file\n",
    "#name_movie = \"baseline_new_loss_v2.gif\"\n",
    "\n",
    "movie_rec = \"movie_\"+name_vae+\"_rec.gif\"\n",
    "\n",
    "frame_per_second = 2\n",
    "im = mpy.ImageSequenceClip(rec_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_rec, fps=frame_per_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_rec+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_rec(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:9],n_col=3,n_padding=4,title=\"REFERENCE\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
