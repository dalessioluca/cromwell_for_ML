{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKELETON OF JUPYTER NOTEBOOK WHICH CAN BE RUN WITH CROMWELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the file \"parameters.json\" from the execution directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wdl.alias': 'acbd', 'wdl.memo': 'this is the baseline run', 'wdl.file_train': 'gs://input_bucket_name/path_to_file/train_dataset.pkl', 'wdl.file_test': 'gs://input_bucket_name/path_to_file/test_dataset.pkl', 'wdl.file_ckpt': 'gs://input_bucket_name/path_to_file/ckp.pkl', 'wdl.bucket_output': 'gs://output_bucket_name', 'wdl.dir_output': 'output', 'wdl.notebook_name': 'main.ipynb', 'wdl.git_repo': 'https://github.com/dalessioluca/cromwell_for_ML.git', 'wdl.commit_or_branch': 'master', 'example_params_1': {'__comment': 'add here any parameters for your simulation', 'N_MAX_EPOCHS': 10, 'lr': 0.01, 'noise': 0.2}, 'example_params_2': {'__comment': 'more parameters if needed', 'n_feature': 1, 'n_hidden': 10, 'n_output': 1}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"parameters.json\", 'rb') as f:\n",
    "    params = json.load(f)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create outout directory if it does not exist yet.prepare the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset.pkl\n",
      "test_dataset.pkl\n",
      "output\n",
      "output/parameters.json\n"
     ]
    }
   ],
   "source": [
    "# CROMWELL + WDL  will localize: \n",
    "# gs://bucket_name/path_to_file/dataset.pkl -> execution_dir/dataset.pkl\n",
    "\n",
    "train_file = os.path.basename(params[\"wdl.file_train\"])\n",
    "test_file = os.path.basename(params[\"wdl.file_test\"])\n",
    "ckpt_file = os.path.basename(params[\"wdl.file_ckpt\"])\n",
    "dir_output = params[\"wdl.dir_output\"]\n",
    "\n",
    "# create output directory if it does nto exists\n",
    "try:\n",
    "    os.mkdir(dir_output)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "# Save input_json_file to output dir\n",
    "json_param_file = os.path.join(dir_output, \"parameters.json\")\n",
    "with open(json_param_file, 'w') as f:\n",
    "    json.dump(params, f)\n",
    "\n",
    "print(train_file)\n",
    "print(test_file)\n",
    "print(dir_output)\n",
    "print(json_param_file)\n",
    "\n",
    "# checks inputs file are presents\n",
    "#assert os.path.isfile(train_file)\n",
    "#assert os.path.isfile(test_file)\n",
    "#assert os.path.isfile(ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put here your code\n",
    "Here is a dumm example of linear regression or example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MAX_EPOCHS = params[\"example_params_1\"][\"N_MAX_EPOCHS\"]\n",
    "LR = params[\"example_params_1\"][\"lr\"]\n",
    "NOISE = params[\"example_params_1\"][\"noise\"]\n",
    "N_FEATURE = params[\"example_params_2\"][\"n_feature\"]\n",
    "N_HIDDEN = params[\"example_params_2\"][\"n_hidden\"]\n",
    "N_OUTPUT = params[\"example_params_2\"][\"n_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset\n",
    "In the real situation you load the dataset from the train_file and test_file\n",
    "Here we make a fake dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(1)    # reproducible\n",
    "x = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1).requires_grad_(False)  # x data (tensor), shape=(100, 1)\n",
    "y = x.pow(2) + NOISE*torch.rand(x.size()).requires_grad_(False)               # noisy y data (tensor), shape=(100, 1)\n",
    "\n",
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "#plt.yscale('log')\n",
    "#plt.xlim(xmin=1.0, xmax=1.5)\n",
    "ax.set_xlabel('Independent varible',fontsize=fontsize)\n",
    "ax.set_ylabel('Dependent varible',fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax.plot(x,y, 'o')\n",
    "ax.grid()\n",
    "fig.tight_layout()\n",
    "tmp_file = os.path.join(dir_output, \"input_data.png\")\n",
    "fig.savefig(tmp_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "In the real case you will import what you need from github repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(MLP, self).__init__()\n",
    "        self.predict = torch.nn.Sequential(\n",
    "            torch.nn.Linear(n_feature, n_hidden),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(n_hidden, n_output) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.predict(x)\n",
    "\n",
    "net = MLP(n_feature=N_FEATURE, n_hidden=N_HIDDEN, n_output=N_OUTPUT)    \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=LR)\n",
    "criterion = torch.nn.MSELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch ->   0, loss= 0.663\n",
      "epoch ->   1, loss= 0.566\n",
      "epoch ->   2, loss= 0.485\n",
      "epoch ->   3, loss= 0.419\n",
      "epoch ->   4, loss= 0.363\n",
      "epoch ->   5, loss= 0.317\n",
      "epoch ->   6, loss= 0.279\n",
      "epoch ->   7, loss= 0.247\n",
      "epoch ->   8, loss= 0.220\n",
      "epoch ->   9, loss= 0.199\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "\n",
    "for epoch in range(N_MAX_EPOCHS):\n",
    "  \n",
    "    prediction = net(x)     \n",
    "    loss = criterion(prediction, y) \n",
    "    loss_history.append(loss.detach().item())\n",
    "    \n",
    "    # next 3 lines to do back_prop\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    print(\"epoch -> %3d, loss= %.3f\" %(epoch,loss_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "    \n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-19-ebc3ff9cb30c>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-ebc3ff9cb30c>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "\n",
    "NEPOCHS = params[\"example_params_1\"][\"NEPOCHS\"]\n",
    "LR = params[\"example_params_1\"][\"NEPOCHS\"]\n",
    "\n",
    "pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "loss_history = []\n",
    "for i in range(NEPOCHS):\n",
    "    # train loop\n",
    "    net = NET()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VaeClass(params)\n",
    "optimizer = instantiate_optimizer(vae, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are 3 possible simulation types: scratch, resumed, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"simulation type = \"+str(params[\"simulation\"][\"type\"]))\n",
    "\n",
    "if (params[\"simulation\"][\"type\"] == \"scratch\"):\n",
    "    \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"resumed\"):\n",
    "        \n",
    "    resumed = load_info(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                        load_epoch=True, \n",
    "                        load_history=True)\n",
    "    epoch_restart = resumed.epoch\n",
    "    history_dict = resumed.history_dict\n",
    "    min_test_loss = min(history_dict[\"test_loss\"])\n",
    "    \n",
    "    load_model_optimizer(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                         model=vae,\n",
    "                         optimizer=optimizer)\n",
    "\n",
    "elif (params[\"simulation\"][\"type\"] == \"pretrained\"):\n",
    "       \n",
    "    epoch_restart = -1\n",
    "    history_dict = {}\n",
    "    min_test_loss = 99999999\n",
    "    \n",
    "    load_model_optimizer(path=params[\"simulation\"][\"path_to_file\"], \n",
    "                         model=vae,\n",
    "                         optimizer=None)\n",
    "    \n",
    "# instantiate the scheduler if necessary    \n",
    "if params[\"training\"][\"scheduler_is_active\"]:\n",
    "    scheduler = instantiate_scheduler(optimizer, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FREQUENCY = params[\"training\"][\"TEST_FREQUENCY\"]\n",
    "CHECKPOINT_FREQUENCY = params[\"training\"][\"CHECKPOINT_FREQUENCY\"]\n",
    "NUM_EPOCHS = params[\"training\"][\"EPOCHS\"]\n",
    "BATCH_SIZE = params[\"training\"][\"batch_size\"]\n",
    "\n",
    "for delta_epoch in range(1,NUM_EPOCHS+1):\n",
    "    epoch = delta_epoch+epoch_restart\n",
    "    vae.train()   \n",
    "    \n",
    "    #with torch.autograd.set_detect_anomaly(True):\n",
    "    with torch.autograd.set_detect_anomaly(False):\n",
    "        train_metrics = train_one_epoch(vae, \n",
    "                                        train_dataset, \n",
    "                                        optimizer, \n",
    "                                        BATCH_SIZE, \n",
    "                                        verbose=(epoch==0), \n",
    "                                        weight_clipper=None)\n",
    "        s = pretty_print_metrics(epoch, train_metrics, is_train=True)\n",
    "        print(s)\n",
    "            \n",
    "        \n",
    "        history_dict = add_named_tuple_to_dictionary(namedtuple=train_metrics, \n",
    "                                                     dictionary=history_dict,\n",
    "                                                     key_prefix=\"train_\")\n",
    "        \n",
    "    if params[\"training\"][\"scheduler_is_active\"]:\n",
    "        scheduler.step(epoch=epoch)\n",
    "    \n",
    "    if(epoch % TEST_FREQUENCY == 0):\n",
    "        vae.eval()\n",
    "        test_metrics = train_one_epoch(vae, \n",
    "                                       test_dataset, \n",
    "                                       optimizer, \n",
    "                                       BATCH_SIZE, \n",
    "                                       verbose=(epoch==0), \n",
    "                                       weight_clipper=None)\n",
    "        \n",
    "        s = pretty_print_metrics(epoch, test_metrics, is_train=False)\n",
    "        print(s)\n",
    "                \n",
    "        history_dict = add_named_tuple_to_dictionary(namedtuple=test_metrics, \n",
    "                                                     dictionary=history_dict,\n",
    "                                                     key_prefix=\"test_\")\n",
    "        \n",
    "        test_loss = test_metrics[\"loss\"]\n",
    "        min_test_loss = min(min_test_loss, test_loss)\n",
    "            \n",
    "        #if((test_loss == min_test_loss) or ((epoch % CHECKPOINT_FREQUENCY) == 0)): \n",
    "        if((test_loss == min_test_loss) or ((epoch % TEST_FREQUENCY) == 0)):\n",
    "            checkpoint_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "            history_file = os.path.join(dir_output, \"history_\"+str(epoch)+\".pkl\")\n",
    "            \n",
    "            save_everything(model=vae, \n",
    "                            optimizer=optimizer, \n",
    "                            history_dict=history_dict, \n",
    "                            epoch=epoch, \n",
    "                            params_dict=params, \n",
    "                            path=checkpoint_file)\n",
    "            \n",
    "            save_dict_as_json(history_dict, path=history_file)\n",
    "            print(\"saved files -> \"+checkpoint_file+\"  \"+history_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in history_dict.items():\n",
    "    print(k,\" -->\", history_dict[k][-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.yscale('log')\n",
    "y_shift=0\n",
    "x_shift=0\n",
    "sign=1\n",
    "\n",
    "fontsize=10\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('REC',fontsize=fontsize)\n",
    "ax.set_ylabel('REG',fontsize=fontsize)\n",
    "\n",
    "ax.plot(np.arange(x_shift, x_shift+len(history_dict[\"train_loss\"])), sign*np.array(history_dict[\"train_loss\"])+y_shift,'-')\n",
    "ax.plot(np.arange(x_shift, x_shift+len(history_dict[\"test_loss\"])*TEST_FREQUENCY,TEST_FREQUENCY), sign*np.array(history_dict[\"test_loss\"])+y_shift, '.--')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('LOSS = - ELBO')\n",
    "ax.set_title('Training procedure')\n",
    "ax.grid(True)\n",
    "ax.legend(['train', 'test_clean', 'test_noisy'])\n",
    "\n",
    "fig.tight_layout()\n",
    "tmp_file = os.path.join(dir_output, \"loss.png\")\n",
    "fig.savefig(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot of KL vs evidence\n",
    "fontsize=20\n",
    "labelsize=20\n",
    "\n",
    "how_many = 2000\n",
    "scale= 1\n",
    "N = len(history_dict[\"train_kl\"][-how_many :])\n",
    "colors = np.arange(0.0,N,1.0)/N\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "#plt.yscale('log')\n",
    "#plt.xlim(xmin=1.0, xmax=1.5)\n",
    "ax.set_xlabel('REC',fontsize=fontsize)\n",
    "ax.set_ylabel('REG',fontsize=fontsize)\n",
    "ax.tick_params(axis='both', which='major', labelsize=labelsize)\n",
    "ax.scatter(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :],c=colors)\n",
    "ax.plot(history_dict[\"train_nll\"][-how_many :], history_dict[\"train_kl\"][-how_many :], '-')\n",
    "ax.grid()\n",
    "#plt.xlim(xmax=2.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "tmp_file = os.path.join(dir_output, \"rec_kl_trajectory.png\")\n",
    "fig.savefig(tmp_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp_list = [291, 413, 133, 148, 1,2,3,4,5,6,7,8,9]\n",
    "reference_imgs, labels=test_dataset.load(batch_size=9, indices=tmp_list)\n",
    "metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "\n",
    "reconstruction_file = os.path.join(dir_output, \"imgs_reconstructed.png\")\n",
    "reference_file = os.path.join(dir_output, \"imgs_reference.png\")\n",
    "\n",
    "imgs_ref = show_batch(reference_imgs[:],n_col=3,n_padding=4,title=\"REFERENCE\")\n",
    "imgs_ref.savefig(reference_file)\n",
    "\n",
    "imgs_rec = show_batch(inference.reconstruction, n_col=3,n_padding=4, title=\"REC_IMG\")\n",
    "imgs_rec.savefig(reconstruction_file)\n",
    "\n",
    "display(imgs_rec, imgs_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE MOVIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=\"xxx\"\n",
    "a = show_batch(inference.reconstruction[:9],n_col=3,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_filenames = []\n",
    "\n",
    "for epoch in range(0,300,TEST_FREQUENCY):\n",
    "    if(epoch<10):\n",
    "        label =\"_000\"+str(epoch)\n",
    "    elif(epoch<100):\n",
    "        label = \"_00\"+str(epoch)\n",
    "    elif(epoch<1000):\n",
    "        label = \"_0\"+str(epoch)\n",
    "    elif(epoch<10000):\n",
    "        label = \"_\"+str(epoch)\n",
    "    else:\n",
    "        raise Exception\n",
    "\n",
    "    try:\n",
    "        checkpoint_file = os.path.join(dir_output, \"ckp_\"+str(epoch)+\".pkl\")\n",
    "        _ = load_model_optimizer(path=checkpoint_file, model=vae, optimizer=None)\n",
    "        metric, inference = vae.reconstruct_img(reference_imgs)\n",
    "        tmp_fig = show_batch(inference.reconstruction[:8],n_col=4,n_padding=4,title=\"EPOCH = \"+str(epoch))\n",
    "        tmp_rec_file = os.path.join(dir_output, \"imgs_rec\"+label+\".png\")\n",
    "        rec_filenames.append(tmp_rec_file)\n",
    "        tmp_fig.savefig(tmp_rec_file, bbox_inches='tight') \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(rec_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frame_rec(n):\n",
    "    tmp = Image(filename=rec_filenames[n])\n",
    "    return display(tmp)\n",
    "\n",
    "def show_frame_all(n):\n",
    "    c = Image(filename=rec_filenames[n])\n",
    "    return display(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make gif file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_rec_file_local = \"movie_rec.gif\"\n",
    "movie_rec_file_absolute = os.path.join(dir_output, movie_rec_file_local)\n",
    "\n",
    "frame_per_second = 2\n",
    "im = mpy.ImageSequenceClip(rec_filenames, fps=frame_per_second)\n",
    "im.write_gif(movie_rec_file_local, fps=frame_per_second)\n",
    "im.write_gif(movie_rec_file_absolute, fps=frame_per_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"<img src=\"+movie_rec_file_local+\"></img>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame_rec(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(reference_imgs[:8],n_col=4,n_padding=4,title=\"REFERENCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
