{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MINIMAL EXAMPLE OF JUPYTER NOTEBOOK WHICH CAN BE RUN WITH CROMWELL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem is that it produces run2.html and trial_v1_movie_rec.gif in local folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" #for debugging, it decrease performance dramatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyro.__version__  -->  0.4.0\n",
      "torch.__version__ -->  1.2.0\n"
     ]
    }
   ],
   "source": [
    "from utilities import *\n",
    "from vae_model import * \n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "\n",
    "# Set up pyro environment\n",
    "pyro.clear_param_store()\n",
    "pyro.set_rng_seed(0)\n",
    "\n",
    "# Check versions\n",
    "print(\"pyro.__version__  --> \",pyro.__version__)\n",
    "print(\"torch.__version__ --> \",torch.__version__)\n",
    "#assert(pyro.__version__.startswith('0.4'))\n",
    "#assert(torch.__version__.startswith('1.2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read two json files and combine in single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_ml_with_wdl.train_data': 'gs://ld-data-bucket/data/fashionmnist_train.pkl', 'run_ml_with_wdl.test_data': 'gs://ld-data-bucket/data/fashionmnist_test.pkl', 'run_ml_with_wdl.checkpoint': 'gs://ld-results-bucket/ckpt/dummy.pkl', 'run_ml_with_wdl.bucket_output': 'gs://ld-results-bucket/', 'run_ml_with_wdl.notebook_name': 'test.ipynb', 'run_ml_with_wdl.git_repo': 'https://github.com/dalessioluca/cromwell_for_ML.git', 'run_ml_with_wdl.commit_or_branch': 'master', 'simulation': {'__comment': 'there are 3 types of runs: scratch resume pre_trained', 'manual_or_wdl': 'wdl', 'output_dir': 'trial_v1', 'type': 'scratch'}, 'architecture': {'__comment': 'parameters specifying the architecture of the model', 'dim_zwhat': 25, 'width_input_image': 28, 'ch_input_image': 1}, 'loss': {'__comment': 'parameter of the observation model', 'mse_sigma': 0.1}, 'optimizer': {'__comment': 'which optimizer to use', 'type': 'adam', 'lr': 0.001, 'betas': [0.9, 0.999], 'eps': 1e-08}, 'training': {'__comment': 'parameter of the observation model', 'EPOCHS': 6, 'TEST_FREQUENCY': 5, 'CHECKPOINT_FREQUENCY': 20, 'batch_size': 64, 'scheduler_is_active': False, 'scheduler_type': 'step_LR', 'scheduler_step_size': 100, 'scheduler_gamma': 0.75}}\n"
     ]
    }
   ],
   "source": [
    "params = load_json_as_dict(\"./input_for_wdl.json\")  \n",
    "params2 = load_json_as_dict(\"./other_inputs.json\")\n",
    "params.update(params2)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params[\"simulation\"][\"manual_or_wdl\"] == \"manual\":\n",
    "    # the google bucket information is replaced by \"./\"\n",
    "    # prepare input file and check if exist\n",
    "    train_tmp = params[\"run_ml_with_wdl.train_data\"].split(\"/\")\n",
    "    test_tmp = params[\"run_ml_with_wdl.test_data\"].split(\"/\")\n",
    "    ckpt_tmp = params[\"run_ml_with_wdl.checkpoint\"].split(\"/\")\n",
    "    train_file = os.path.join(train_tmp[-2],train_tmp[-1])\n",
    "    test_file = os.path.join(test_tmp[-2],test_tmp[-1])\n",
    "    ckpt_file = os.path.join(ckpt_tmp[-2],ckpt_tmp[-1])\n",
    "    \n",
    "    # prepare output files\n",
    "    output_bucket = None\n",
    "    output_dir = os.path.basename(params[\"simulation\"][\"output_dir\"])\n",
    "    try:\n",
    "        os.mkdir(output_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "else:\n",
    "    \n",
    "    # At this point WDL has localized the files in the work directory\n",
    "    # Therefore just grab basename\n",
    "    train_file = os.path.basename(params[\"run_ml_with_wdl.train_data\"])\n",
    "    test_file = os.path.basename(params[\"run_ml_with_wdl.train_data\"])\n",
    "    ckpt_file = os.path.basename(params[\"run_ml_with_wdl.checkpoint\"])\n",
    "    \n",
    "    # prepare output directory and check if exist\n",
    "    output_bucket = params[\"run_ml_with_wdl.bucket_output\"]\n",
    "    output_dir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "trial_v1\n",
      "data/fashionmnist_train.pkl\n",
      "data/fashionmnist_test.pkl\n",
      "trial_v1/jupyter.log\n",
      "trial_v1/all_inputs.json\n",
      "/Users/ldalessi/cromwell_for_ML\n"
     ]
    }
   ],
   "source": [
    "# checks\n",
    "#assert os.path.isfile(train_file)\n",
    "#assert os.path.isfile(test_file)\n",
    "print(os.path.isfile(train_file))\n",
    "print(os.path.isfile(test_file))\n",
    "if params[\"simulation\"][\"type\"] != \"scratch\":\n",
    "    #assert os.path.isfile(ckpt_file)\n",
    "    print(os.path.isfile(ckpt_file))\n",
    "    \n",
    "json_param_file = os.path.join(output_dir, \"all_inputs.json\")\n",
    "log_file = os.path.join(output_dir, \"jupyter.log\")\n",
    "    \n",
    "print(output_bucket)\n",
    "print(output_dir)\n",
    "print(train_file)\n",
    "print(test_file)\n",
    "print(log_file)\n",
    "print(json_param_file)\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "print(cur_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start logging some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "luca_logging: 2020-02-28 17:27:33\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"luca_logging: %(message)s\",\n",
    "                    filename=log_file,\n",
    "                    filemode=\"w\")\n",
    "console = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\"luca_logging: %(message)s\")\n",
    "console.setFormatter(formatter)  # Use the same format for stdout.\n",
    "logging.getLogger('').addHandler(console)  # Log to stdout and a file.\n",
    "\n",
    "# Log the start time.\n",
    "logging.info(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "luca_logging: saving input json in output directory\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"saving input json in output directory\")\n",
    "save_dict_as_json(params,json_param_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
